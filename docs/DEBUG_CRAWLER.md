# ğŸ› Script de Debug con Puppeteer - DocumentaciÃ³n TÃ©cnica

## ğŸ“‹ Resumen

El script `debug-crawler.js` es una herramienta de debugging exhaustiva que utiliza Puppeteer para navegar automÃ¡ticamente por toda la aplicaciÃ³n React, detectar rutas, capturar errores y generar logs detallados para anÃ¡lisis posterior.

## ğŸ¯ Objetivos

1. **Mapeo completo de rutas**: Descubrir todas las rutas disponibles en la aplicaciÃ³n
2. **DetecciÃ³n de errores**: Identificar errores HTTP, JavaScript y de renderizado
3. **Captura de logs**: Registrar todos los logs de consola del navegador
4. **GeneraciÃ³n de reportes**: Crear logs estructurados para anÃ¡lisis con IA

## ğŸ—ï¸ Arquitectura

### Flujo de EjecuciÃ³n

```
1. InicializaciÃ³n
   â”œâ”€â”€ Crear directorio debug/
   â”œâ”€â”€ Generar archivo de log con timestamp
   â””â”€â”€ Configurar logging

2. Inicio de Puppeteer
   â”œâ”€â”€ Lanzar navegador (headless: false para debug)
   â”œâ”€â”€ Configurar timeouts
   â””â”€â”€ Configurar captura de logs de consola

3. AutenticaciÃ³n
   â”œâ”€â”€ Intentar login en /login
   â”œâ”€â”€ Intentar login en /admin
   â””â”€â”€ Intentar login en /contrato/login

4. NavegaciÃ³n
   â”œâ”€â”€ Visitar rutas conocidas
   â”œâ”€â”€ Extraer links de cada pÃ¡gina
   â”œâ”€â”€ Visitar links encontrados (con lÃ­mite de profundidad)
   â””â”€â”€ Detectar rutas con parÃ¡metros dinÃ¡micos

5. GeneraciÃ³n de Reporte
   â”œâ”€â”€ EstadÃ­sticas generales
   â”œâ”€â”€ Lista de rutas encontradas
   â”œâ”€â”€ Lista de URLs visitadas
   â”œâ”€â”€ Errores encontrados
   â””â”€â”€ Logs de consola (Ãºltimos 50)
```

## ğŸ”§ Componentes Principales

### 1. Sistema de Logging

El script implementa un sistema de logging multi-nivel:

```javascript
log.file(message)    // Log general
log.error(message)   // Errores
log.success(message) // Ã‰xitos
log.info(message)    // InformaciÃ³n
log.separator()      // Separadores visuales
```

Todos los logs se escriben tanto en consola como en el archivo de log.

### 2. Captura de Logs de Consola

El script configura listeners para capturar todos los eventos de consola:

- `page.on('console')` - Captura console.log, console.error, etc.
- `page.on('pageerror')` - Captura errores de JavaScript no capturados
- `page.on('response')` - Captura respuestas HTTP con errores
- `page.on('requestfailed')` - Captura requests que fallan

### 3. DetecciÃ³n de Rutas con ParÃ¡metros

El script normaliza rutas con parÃ¡metros dinÃ¡micos usando patrones regex:

```javascript
const routePatterns = [
  { pattern: /\/contacts\/\d+/, replacement: '/contacts/:id' },
  { pattern: /\/leads\/\d+/, replacement: '/leads/:id' },
  { pattern: /\/users\/\d+/, replacement: '/users/:id' },
  { pattern: /\/hiring\/[A-Z0-9]{5}/, replacement: '/hiring/:code' },
];
```

### 4. Sistema de Visitas

El script mantiene un `Set` de URLs visitadas para evitar:
- Visitas duplicadas
- Loops infinitos
- NavegaciÃ³n innecesaria

### 5. NavegaciÃ³n con Profundidad Limitada

Para evitar navegaciÃ³n infinita, el script implementa un sistema de profundidad:

```javascript
async function visitUrl(url, depth = 0, maxDepth = 5)
```

- `depth`: Profundidad actual de navegaciÃ³n
- `maxDepth`: MÃ¡ximo permitido (por defecto 5)

## ğŸ“Š Estructura del Log

### Encabezado

```
================================================================================
ğŸš€ Iniciando crawler de debug
ğŸ“… Fecha: [timestamp]
ğŸŒ URL Base: [URL]
ğŸ“§ Email: [email]
ğŸ“ Archivo de log: [ruta del archivo]
================================================================================
```

### Durante la EjecuciÃ³n

Cada acciÃ³n se registra con timestamp:

```
[2025-12-15T15:30:45.123Z] â„¹ï¸  ğŸ” Intentando hacer login...
[2025-12-15T15:30:47.456Z] âœ… Login exitoso desde /admin
[2025-12-15T15:30:50.789Z] ğŸ” Visitando: http://localhost:5173/admin/dashboard
[2025-12-15T15:30:52.012Z] âœ… Visitada: http://localhost:5173/admin/dashboard -> Ruta: /admin/dashboard
```

### Reporte Final

```
================================================================================
ğŸ“Š REPORTE FINAL
================================================================================

ğŸ“ˆ ESTADÃSTICAS:
   - URLs visitadas: [nÃºmero]
   - Rutas Ãºnicas encontradas: [nÃºmero]
   - Errores encontrados: [nÃºmero]
   - Logs de consola capturados: [nÃºmero]

ğŸ—ºï¸  RUTAS ENCONTRADAS ([nÃºmero]):
   1. /ruta1
   2. /ruta2
   ...

ğŸŒ URLs VISITADAS ([nÃºmero]):
   1. http://...
   2. http://...
   ...

âŒ ERRORES ENCONTRADOS ([nÃºmero]):
   1. [descripciÃ³n del error]
   2. [descripciÃ³n del error]
   ...

ğŸ“ LOGS DE CONSOLA (Ãºltimos 50):
   1. [ERROR] [mensaje] (ubicaciÃ³n)
   2. [WARNING] [mensaje] (ubicaciÃ³n)
   ...
```

## ğŸ” Rutas Conocidas

El script visita las siguientes rutas conocidas de la aplicaciÃ³n:

### Admin Routes
- `/admin`
- `/admin/dashboard`
- `/admin/users`
- `/admin/users/create`
- `/admin/audit-logs`
- `/admin/pili`
- `/admin/conversations`

### CRM Routes
- `/crm`
- `/crm/contacts`
- `/crm/leads`
- `/crm/calendar`
- `/crm/actions`
- `/crm/expedientes`
- `/crm/call`
- `/crm/settings`
- `/crm/settings/task-templates`
- `/crm/settings/custom-fields`

### Contrato Routes
- `/contrato`
- `/contrato/login`
- `/contrato/dashboard`

### Public Routes
- `/`
- `/privacidad`
- `/privacy`
- `/borrador`
- `/colaboradores`
- `/closer`

## ğŸ› Manejo de Errores

### Errores de NavegaciÃ³n

Si una URL no se puede visitar, el script:
1. Registra el error en el log
2. Lo agrega a la lista de errores
3. ContinÃºa con la siguiente URL

### Errores de Login

Si el login falla, el script:
1. Intenta mÃºltiples rutas de login
2. Si todas fallan, continÃºa sin autenticaciÃ³n
3. Registra el fallo en el log

### Timeouts

El script maneja timeouts de dos formas:
- **TIMEOUT**: Tiempo mÃ¡ximo para operaciones individuales (30s)
- **NAVIGATION_TIMEOUT**: Tiempo mÃ¡ximo para navegaciÃ³n (60s)

Si se excede un timeout, el script registra el error y continÃºa.

## ğŸ“ Mejoras Futuras

### Posibles Extensiones

1. **Screenshots automÃ¡ticos**: Capturar screenshots de pÃ¡ginas con errores
2. **Performance metrics**: Medir tiempos de carga de cada pÃ¡gina
3. **Accessibility testing**: Integrar tests de accesibilidad
4. **Visual regression**: Comparar screenshots entre versiones
5. **API monitoring**: Monitorear llamadas a la API durante la navegaciÃ³n
6. **Export a JSON**: Generar reporte en formato JSON para procesamiento automatizado

### Optimizaciones

1. **ParalelizaciÃ³n**: Visitar mÃºltiples pÃ¡ginas en paralelo (con cuidado)
2. **Caching**: Cachear resultados de navegaciÃ³n para evitar re-visitas
3. **Selective crawling**: Permitir especificar quÃ© rutas visitar
4. **Resume capability**: Poder reanudar un crawl interrumpido

## ğŸ”’ Consideraciones de Seguridad

### Credenciales

âš ï¸ **IMPORTANTE**: El script contiene credenciales hardcodeadas. Para producciÃ³n:

1. Usar variables de entorno:
```javascript
const LOGIN_EMAIL = process.env.DEBUG_EMAIL;
const LOGIN_PASSWORD = process.env.DEBUG_PASSWORD;
```

2. No commiteear el archivo con credenciales reales
3. Usar credenciales de test/staging cuando sea posible

### InformaciÃ³n Sensible

El log puede contener informaciÃ³n sensible:
- URLs internas
- Errores que revelan estructura
- Logs de consola con datos

AsegÃºrate de revisar los logs antes de compartirlos.

## ğŸ“š Referencias

- [Puppeteer Documentation](https://pptr.dev/)
- [React Router Documentation](https://reactrouter.com/)
- [Node.js File System](https://nodejs.org/api/fs.html)

## ğŸ¤ Contribuciones

Para mejorar el script:

1. Agregar nuevas rutas conocidas en `visitKnownRoutes()`
2. Agregar nuevos patrones de rutas en `extractRoutes()`
3. Mejorar el manejo de errores especÃ­ficos
4. Agregar nuevas mÃ©tricas al reporte



















